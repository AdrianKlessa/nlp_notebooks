{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### A simple neural language model\n",
    "\n",
    "Trained with PyTorch on public domain books from Project Gutenberg"
   ],
   "id": "4e7f5d3f09790056"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loading the data",
   "id": "94f94fd6d58d70b4"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-02T15:11:15.884575Z",
     "start_time": "2025-05-02T15:11:14.888237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from typing import Sequence\n",
    "import nltk\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "\n",
    "books = [f for f in listdir(\"data/sherlock_holmes\") if isfile(join(\"data/sherlock_holmes\", f))]\n",
    "text = \"\"\n",
    "for book in books:\n",
    "    filepath = \"data/sherlock_holmes/\" + book\n",
    "    with open(filepath, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        text +=\" \"+ f.read()\n",
    "additional_books = [\"all quiet on the western front.txt\",\"count of monte cristo.txt\", \"war and peace.txt\", \"ulysses.txt\", \"don quixote.txt\"]\n",
    "\n",
    "for book in additional_books:\n",
    "    filepath = \"data/\" + book\n",
    "    with open(filepath, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        text +=\" \"+ f.read()"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Some simple processing\n",
    "\n",
    "All text to lowercase, dividing into sentences, tokenization"
   ],
   "id": "a35a9693f4d159bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:11:25.971761Z",
     "start_time": "2025-05-02T15:11:15.891749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = text.replace(\"\\n\", \" \")\n",
    "text = text.lower()\n",
    "\n",
    "\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "tokenized = []\n",
    "for sentence in sentences:\n",
    "    tokenized.append(nltk.word_tokenize(sentence))\n",
    "padded_tokenized = []\n",
    "\n",
    "for tokenized_sentence in tokenized:\n",
    "    padded_tokenized.append(list(pad_both_ends(tokenized_sentence, n=2)))"
   ],
   "id": "a285c26b8b063ebb",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:11:26.190368Z",
     "start_time": "2025-05-02T15:11:26.186786Z"
    }
   },
   "cell_type": "code",
   "source": "print(padded_tokenized[0])",
   "id": "da6d61220bef1ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'the', 'project', 'gutenberg', 'ebook', 'of', 'a', 'study', 'in', 'scarlet', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'united', 'states', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', '.', '</s>']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:11:26.202705Z",
     "start_time": "2025-05-02T15:11:26.196592Z"
    }
   },
   "cell_type": "code",
   "source": "len(padded_tokenized)",
   "id": "cca4d2df203063da",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112674"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Preparing into a x / y format for NN input",
   "id": "1524a645a1347f80"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:11:29.339926Z",
     "start_time": "2025-05-02T15:11:26.267438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(42)\n",
    "CONTEXT_SIZE = 4\n",
    "EMBEDDING_DIM = 10\n",
    "ngrams = [\n",
    "    (\n",
    "        #(sent[i-2],sent[i-1],sent[i+1], sent[i+2]),\n",
    "        tuple([sent[i-j] for j in range(CONTEXT_SIZE, 0, -1)]),\n",
    "        sent[i]\n",
    "    )\n",
    "    for sent in padded_tokenized for i in range(CONTEXT_SIZE+1, len(sent))\n",
    "]\n",
    "\n",
    "print(ngrams[:7])"
   ],
   "id": "bb7eb77e4fb42e4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('the', 'project', 'gutenberg', 'ebook'), 'of'), (('project', 'gutenberg', 'ebook', 'of'), 'a'), (('gutenberg', 'ebook', 'of', 'a'), 'study'), (('ebook', 'of', 'a', 'study'), 'in'), (('of', 'a', 'study', 'in'), 'scarlet'), (('a', 'study', 'in', 'scarlet'), 'this'), (('study', 'in', 'scarlet', 'this'), 'ebook')]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:11:29.354403Z",
     "start_time": "2025-05-02T15:11:29.350031Z"
    }
   },
   "cell_type": "code",
   "source": "len(ngrams)",
   "id": "95209118affa5549",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2635154"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:11:30.054462Z",
     "start_time": "2025-05-02T15:11:29.369946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(ngrams, shuffle=True)\n",
    "print(len(train), len(test))"
   ],
   "id": "e615a50c7be1c8fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1976365 658789\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setting up a dictionary for tokenization",
   "id": "ae29964e59f5468d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:11:35.949949Z",
     "start_time": "2025-05-02T15:11:30.060518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "train_all_words = [x for x in itertools.chain.from_iterable([[example[1]]+[x for x in example[0]] for example in train])]\n",
    "train_vocab = set(train_all_words)\n",
    "print(list(train_vocab)[:5])"
   ],
   "id": "50bdf5cf22dd3c16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['des', 'c08c.jpg', 'ironmongery', '20139m', 'capel']\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:11:37.554976Z",
     "start_time": "2025-05-02T15:11:35.992451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "vocab_size = 20_000\n",
    "vocab = build_vocab_from_iterator([train_all_words], max_tokens=vocab_size, specials = ['<unk>'])\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "print(vocab['he'])"
   ],
   "id": "73fb8d27a5e4c31d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:11:37.596498Z",
     "start_time": "2025-05-02T15:11:37.591498Z"
    }
   },
   "cell_type": "code",
   "source": "vocab.lookup_tokens([0, 1, 2, 10,2500, 12345])",
   "id": "656ea17c6d02ef82",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', ',', 'the', 'that', 'falls', 'pegs']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:11:44.397411Z",
     "start_time": "2025-05-02T15:11:37.636507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_tokenized = []\n",
    "\n",
    "for example in train:\n",
    "    x = tuple([vocab[x] for x in example[0]])\n",
    "    y = vocab[example[1]]\n",
    "    train_tokenized.append((x, y))\n",
    "\n",
    "print(vocab.lookup_tokens(train_tokenized[1][0]))"
   ],
   "id": "8f009e5c85ad148",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['still', ',', 'it', 'is']\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:11:44.437988Z",
     "start_time": "2025-05-02T15:11:44.434099Z"
    }
   },
   "cell_type": "code",
   "source": "print(vocab.lookup_token(train_tokenized[1][1]))",
   "id": "3c7fb779b00d815c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "better\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:11:44.482809Z",
     "start_time": "2025-05-02T15:11:44.478727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import IterableDataset\n",
    "\n",
    "class CustomDataset(IterableDataset):\n",
    "  def __init__(self, example_list):\n",
    "      self.example_list = example_list\n",
    "\n",
    "  def __iter__(self):\n",
    "     return iter(self.example_list)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "      return self.example_list[index]\n",
    "\n",
    "  def __len__(self):\n",
    "      return len(self.example_list)\n",
    "\n",
    "train_dataset = CustomDataset(train_tokenized)"
   ],
   "id": "7f0f6b5b5108358a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:11:46.787722Z",
     "start_time": "2025-05-02T15:11:44.520578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "valid_tokenized = []\n",
    "\n",
    "for example in test:\n",
    "    x = tuple([vocab[x] for x in example[0]])\n",
    "    y = vocab[example[1]]\n",
    "    valid_tokenized.append((x, y))\n",
    "\n",
    "valid_dataset = CustomDataset(valid_tokenized)"
   ],
   "id": "b13c9a63eba15657",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T16:23:12.635899Z",
     "start_time": "2025-05-02T16:23:12.633245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = next(iter(train_dataset))\n",
    "print(res)"
   ],
   "id": "d4328578f0a36f08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((124, 10245, 303, 18), 8)\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T16:23:31.413946Z",
     "start_time": "2025-05-02T16:23:31.410721Z"
    }
   },
   "cell_type": "code",
   "source": "vocab.lookup_tokens([i for i in res[0]])",
   "id": "e45235c0612c5e1b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['old', 'dan', 'o', '’']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T16:23:52.281571Z",
     "start_time": "2025-05-02T16:23:52.276252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def custom_collate(batch):\n",
    "    contexts, targets = zip(*batch)\n",
    "    return torch.tensor(contexts), torch.tensor(targets)\n",
    "\n",
    "res = next(iter(DataLoader(train_dataset, batch_size=5, collate_fn=custom_collate)))\n",
    "print(res)"
   ],
   "id": "3ab9d17823e89848",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[  124, 10245,   303,    18],\n",
      "        [  152,     1,    15,    22],\n",
      "        [   53,     6,    49,     1],\n",
      "        [  300,     3,    11,    57],\n",
      "        [   72,     1,   399,     2]]), tensor([  8, 290,   3,  23, 221]))\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T16:25:18.769716Z",
     "start_time": "2025-05-02T16:25:18.759697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in res[0]:\n",
    "    print(vocab.lookup_tokens(i.tolist()))"
   ],
   "id": "7910ea15a62768e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['old', 'dan', 'o', '’']\n",
      "['still', ',', 'it', 'is']\n",
      "['are', 'a', 'she', ',']\n",
      "['watson', 'and', 'i', 'will']\n",
      "['more', ',', 'during', 'the']\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T16:25:34.342588Z",
     "start_time": "2025-05-02T16:25:34.339263Z"
    }
   },
   "cell_type": "code",
   "source": "print(vocab.lookup_tokens(res[1].tolist()))",
   "id": "e04b6e568bbb862c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'better', 'and', 'not', 'whole']\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Defining the model",
   "id": "70544c52c318287c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:11:47.046081Z",
     "start_time": "2025-05-02T15:11:47.041562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "embed_size = 100\n",
    "\n",
    "class SimpleNeuralLM(nn.Module):\n",
    "  def __init__(self, vocabulary_size, embedding_size, context_size):\n",
    "      super(SimpleNeuralLM, self).__init__()\n",
    "      self.token_embedding = nn.Embedding(vocabulary_size, embedding_size)\n",
    "      self.positional_embedding = nn.Embedding(context_size, embedding_size)\n",
    "      self.linear1 = nn.Linear(embedding_size, 2048)\n",
    "      self.linear2 = nn.Linear(2048, vocabulary_size)\n",
    "      self.register_buffer('position_ids', torch.arange(context_size).unsqueeze(0))\n",
    "\n",
    "  def forward(self, x):\n",
    "      token_embeddings = self.token_embedding(x)\n",
    "      position_embeddings = self.positional_embedding(self.position_ids)\n",
    "      x = token_embeddings + position_embeddings\n",
    "      x = x.mean(dim=1)\n",
    "      x = self.linear1(x)\n",
    "      x = F.relu(x)\n",
    "      x = self.linear2(x)\n",
    "      return F.log_softmax(x, dim=1)"
   ],
   "id": "127b3e0b8350e488",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Making sure that we can train on GPU",
   "id": "86c953391bfa561a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:11:47.112915Z",
     "start_time": "2025-05-02T15:11:47.086437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ],
   "id": "be2ada6a272c544b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2+cu118\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:11:47.549809Z",
     "start_time": "2025-05-02T15:11:47.148394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = 'cuda'\n",
    "model = SimpleNeuralLM(vocab_size, embed_size, CONTEXT_SIZE).to(device)\n",
    "print(model(torch.tensor([[156, 7426, 1, 39]]).to(device)))"
   ],
   "id": "b85a4f98379b701e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-10.0415, -10.1239, -10.2178,  ..., -10.0119,  -9.9341,  -9.7336]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:11:47.596441Z",
     "start_time": "2025-05-02T15:11:47.591439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Number of parameters https://stackoverflow.com/a/49201237\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ],
   "id": "77a0861bbe9b3be9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43187248"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training loop",
   "id": "8d82442b3fab6c6b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T16:03:29.250486Z",
     "start_time": "2025-05-02T15:11:47.640081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = SimpleNeuralLM(vocab_size, embed_size, CONTEXT_SIZE).to(device)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=5000, collate_fn=custom_collate)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=5000, collate_fn=custom_collate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "loss_fn = torch.nn.NLLLoss()\n",
    "\n",
    "MAX_EPOCH_NUMBER = 50\n",
    "PATIENCE = 3\n",
    "patience_counter = 0\n",
    "best_val_loss = float('inf')\n",
    "step = 0\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(MAX_EPOCH_NUMBER):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(x)\n",
    "        loss = loss_fn(y_hat,y)\n",
    "        if step % 100 == 0:\n",
    "           print(step, loss)\n",
    "        step += 1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        if step % 100 == 0:\n",
    "            print(f\"[Train] Step {step}, Loss: {loss.item():.4f}\")\n",
    "        step += 1\n",
    "    avg_train_loss = epoch_loss / len(train_dataloader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in valid_dataloader:\n",
    "            x_val = x_val.to(device)\n",
    "            y_val = y_val.to(device)\n",
    "            y_val_hat = model(x_val)\n",
    "            loss = loss_fn(y_val_hat, y_val)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(valid_dataloader)\n",
    "    valid_losses.append(avg_val_loss)\n",
    "    print(f\"Epoch {epoch}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")\n",
    "        # Early Stopping Check\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        print(\"Validation loss improved. Saving model...\")\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'model_best.bin')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement. Patience {patience_counter}/{PATIENCE}\")\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break"
   ],
   "id": "8ee150b6d26faae3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(9.9167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "100 tensor(6.8878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "200 tensor(6.1121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "300 tensor(6.0450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "400 tensor(5.9636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "500 tensor(5.9188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "600 tensor(5.8459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "700 tensor(5.7657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 0: Train Loss = 6.3098, Val Loss = 5.7884\n",
      "Validation loss improved. Saving model...\n",
      "800 tensor(5.7384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "900 tensor(5.7777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "1000 tensor(5.7878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "1100 tensor(5.6963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "1200 tensor(5.6560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "1300 tensor(5.6542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "1400 tensor(5.6519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "1500 tensor(5.7068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 1: Train Loss = 5.6855, Val Loss = 5.6547\n",
      "Validation loss improved. Saving model...\n",
      "1600 tensor(5.5302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "1700 tensor(5.5673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "1800 tensor(5.6181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "1900 tensor(5.5684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "2000 tensor(5.5787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "2100 tensor(5.5101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "2200 tensor(5.5791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "2300 tensor(5.5559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 2: Train Loss = 5.5637, Val Loss = 5.5869\n",
      "Validation loss improved. Saving model...\n",
      "2400 tensor(5.5180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "2500 tensor(5.5253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "2600 tensor(5.5112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "2700 tensor(5.5365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "2800 tensor(5.5126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "2900 tensor(5.4779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "3000 tensor(5.5451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "3100 tensor(5.5710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 3: Train Loss = 5.4832, Val Loss = 5.5405\n",
      "Validation loss improved. Saving model...\n",
      "3200 tensor(5.3516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "3300 tensor(5.4140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "3400 tensor(5.5063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "3500 tensor(5.4287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "3600 tensor(5.4251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "3700 tensor(5.4369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "3800 tensor(5.3501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "3900 tensor(5.4025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 4: Train Loss = 5.4199, Val Loss = 5.5047\n",
      "Validation loss improved. Saving model...\n",
      "4000 tensor(5.3511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "4100 tensor(5.4117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "4200 tensor(5.4796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "4300 tensor(5.4309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "4400 tensor(5.4122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "4500 tensor(5.3520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "4600 tensor(5.3141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "4700 tensor(5.3916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 5: Train Loss = 5.3666, Val Loss = 5.4753\n",
      "Validation loss improved. Saving model...\n",
      "4800 tensor(5.2810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "4900 tensor(5.3645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "5000 tensor(5.2126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "5100 tensor(5.3391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "5200 tensor(5.2844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "5300 tensor(5.3342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "5400 tensor(5.2865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "5500 tensor(5.2803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 6: Train Loss = 5.3200, Val Loss = 5.4502\n",
      "Validation loss improved. Saving model...\n",
      "5600 tensor(5.2464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "5700 tensor(5.2589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "5800 tensor(5.3017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "5900 tensor(5.2679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "6000 tensor(5.3496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "6100 tensor(5.3489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "6200 tensor(5.2470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "6300 tensor(5.3076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 7: Train Loss = 5.2783, Val Loss = 5.4284\n",
      "Validation loss improved. Saving model...\n",
      "6400 tensor(5.2547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "6500 tensor(5.1841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "6600 tensor(5.3117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "6700 tensor(5.2492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "6800 tensor(5.2392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "6900 tensor(5.2326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "7000 tensor(5.2169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "7100 tensor(5.2047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 8: Train Loss = 5.2403, Val Loss = 5.4091\n",
      "Validation loss improved. Saving model...\n",
      "7200 tensor(5.1877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "7300 tensor(5.2014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "7400 tensor(5.1866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "7500 tensor(5.1788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "7600 tensor(5.2695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "7700 tensor(5.1699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "7800 tensor(5.3141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "7900 tensor(5.1712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 9: Train Loss = 5.2055, Val Loss = 5.3918\n",
      "Validation loss improved. Saving model...\n",
      "8000 tensor(5.2005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "8100 tensor(5.1368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "8200 tensor(5.1618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "8300 tensor(5.1967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "8400 tensor(5.1816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "8500 tensor(5.2214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "8600 tensor(5.1804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "8700 tensor(5.1473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 10: Train Loss = 5.1732, Val Loss = 5.3759\n",
      "Validation loss improved. Saving model...\n",
      "8800 tensor(5.1973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "8900 tensor(5.1549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "9000 tensor(5.1957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "9100 tensor(5.1944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "9200 tensor(5.1987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "9300 tensor(5.1094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "9400 tensor(5.1310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "9500 tensor(5.1932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 11: Train Loss = 5.1430, Val Loss = 5.3614\n",
      "Validation loss improved. Saving model...\n",
      "9600 tensor(5.1203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "9700 tensor(5.1014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "9800 tensor(5.1689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "9900 tensor(5.1764, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "10000 tensor(5.1198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "10100 tensor(5.0895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "10200 tensor(5.1539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 12: Train Loss = 5.1145, Val Loss = 5.3479\n",
      "Validation loss improved. Saving model...\n",
      "10300 tensor(5.1174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "10400 tensor(5.0470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "10500 tensor(5.0807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "10600 tensor(5.0856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "10700 tensor(5.0269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "10800 tensor(5.0364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "10900 tensor(5.0675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "11000 tensor(5.1290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 13: Train Loss = 5.0876, Val Loss = 5.3352\n",
      "Validation loss improved. Saving model...\n",
      "11100 tensor(5.0850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "11200 tensor(5.0863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "11300 tensor(5.0996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "11400 tensor(5.0741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "11500 tensor(5.0510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "11600 tensor(5.0932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "11700 tensor(5.0110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "11800 tensor(5.0232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 14: Train Loss = 5.0621, Val Loss = 5.3234\n",
      "Validation loss improved. Saving model...\n",
      "11900 tensor(5.0683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "12000 tensor(5.0736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "12100 tensor(5.0688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "12200 tensor(5.0297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "12300 tensor(5.0385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "12400 tensor(5.0427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "12500 tensor(5.0626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "12600 tensor(5.0944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 15: Train Loss = 5.0378, Val Loss = 5.3122\n",
      "Validation loss improved. Saving model...\n",
      "12700 tensor(4.9781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "12800 tensor(4.9485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "12900 tensor(4.9234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "13000 tensor(4.9798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "13100 tensor(5.0150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "13200 tensor(4.9875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "13300 tensor(5.0623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "13400 tensor(5.0423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 16: Train Loss = 5.0146, Val Loss = 5.3016\n",
      "Validation loss improved. Saving model...\n",
      "13500 tensor(4.9737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "13600 tensor(4.9619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "13700 tensor(5.0088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "13800 tensor(4.9950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "13900 tensor(5.0368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "14000 tensor(5.0214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "14100 tensor(5.0321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "14200 tensor(5.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 17: Train Loss = 4.9923, Val Loss = 5.2915\n",
      "Validation loss improved. Saving model...\n",
      "14300 tensor(5.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "14400 tensor(5.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "14500 tensor(4.9184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "14600 tensor(4.8859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "14700 tensor(4.9345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "14800 tensor(4.9250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "14900 tensor(4.9693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "15000 tensor(4.9511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 18: Train Loss = 4.9709, Val Loss = 5.2819\n",
      "Validation loss improved. Saving model...\n",
      "15100 tensor(4.9667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "15200 tensor(4.9648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "15300 tensor(4.9835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "15400 tensor(4.8803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "15500 tensor(4.9572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "15600 tensor(4.9730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "15700 tensor(4.9812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "15800 tensor(4.9290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 19: Train Loss = 4.9503, Val Loss = 5.2727\n",
      "Validation loss improved. Saving model...\n",
      "15900 tensor(4.9297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "16000 tensor(4.9785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "16100 tensor(4.9198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "16200 tensor(4.9249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "16300 tensor(4.8915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "16400 tensor(4.9175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "16500 tensor(4.9344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "16600 tensor(4.9300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 20: Train Loss = 4.9305, Val Loss = 5.2640\n",
      "Validation loss improved. Saving model...\n",
      "16700 tensor(4.9075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "16800 tensor(4.9368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "16900 tensor(4.9490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "17000 tensor(4.9245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "17100 tensor(4.7990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "17200 tensor(4.9038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "17300 tensor(4.9370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "17400 tensor(4.8798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 21: Train Loss = 4.9112, Val Loss = 5.2555\n",
      "Validation loss improved. Saving model...\n",
      "17500 tensor(4.8911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "17600 tensor(4.8496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "17700 tensor(4.8951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "17800 tensor(4.9305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "17900 tensor(4.8679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "18000 tensor(4.9390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "18100 tensor(4.9162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "18200 tensor(4.8664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 22: Train Loss = 4.8926, Val Loss = 5.2475\n",
      "Validation loss improved. Saving model...\n",
      "18300 tensor(4.9063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "18400 tensor(4.8666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "18500 tensor(4.8301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "18600 tensor(4.8513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "18700 tensor(4.8545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "18800 tensor(4.8840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "18900 tensor(4.8800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "19000 tensor(4.8736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 23: Train Loss = 4.8746, Val Loss = 5.2397\n",
      "Validation loss improved. Saving model...\n",
      "19100 tensor(4.8107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "19200 tensor(4.8140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "19300 tensor(4.8732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "19400 tensor(4.7850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "19500 tensor(4.8491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "19600 tensor(4.8090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "19700 tensor(4.8912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 24: Train Loss = 4.8571, Val Loss = 5.2322\n",
      "Validation loss improved. Saving model...\n",
      "19800 tensor(4.8950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "19900 tensor(4.8580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "20000 tensor(4.8368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "20100 tensor(4.7991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "20200 tensor(4.8358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "20300 tensor(4.8757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "20400 tensor(4.8030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "20500 tensor(4.8071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 25: Train Loss = 4.8401, Val Loss = 5.2250\n",
      "Validation loss improved. Saving model...\n",
      "20600 tensor(4.8014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "20700 tensor(4.8437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "20800 tensor(4.8857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "20900 tensor(4.8282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "21000 tensor(4.8011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "21100 tensor(4.8289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "21200 tensor(4.8490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "21300 tensor(4.8521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 26: Train Loss = 4.8235, Val Loss = 5.2180\n",
      "Validation loss improved. Saving model...\n",
      "21400 tensor(4.7389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "21500 tensor(4.8146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "21600 tensor(4.8447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "21700 tensor(4.8197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "21800 tensor(4.8254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "21900 tensor(4.7586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "22000 tensor(4.8299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "22100 tensor(4.8057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 27: Train Loss = 4.8073, Val Loss = 5.2113\n",
      "Validation loss improved. Saving model...\n",
      "22200 tensor(4.7971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "22300 tensor(4.8117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "22400 tensor(4.8043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "22500 tensor(4.8198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "22600 tensor(4.8354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "22700 tensor(4.7886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "22800 tensor(4.8513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "22900 tensor(4.8657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 28: Train Loss = 4.7915, Val Loss = 5.2048\n",
      "Validation loss improved. Saving model...\n",
      "23000 tensor(4.7355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "23100 tensor(4.7553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "23200 tensor(4.8469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "23300 tensor(4.7813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "23400 tensor(4.7824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "23500 tensor(4.7858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "23600 tensor(4.7250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "23700 tensor(4.7828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 29: Train Loss = 4.7761, Val Loss = 5.1986\n",
      "Validation loss improved. Saving model...\n",
      "23800 tensor(4.7585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "23900 tensor(4.8174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "24000 tensor(4.8395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "24100 tensor(4.7906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "24200 tensor(4.7897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "24300 tensor(4.7645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "24400 tensor(4.7048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "24500 tensor(4.7906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 30: Train Loss = 4.7610, Val Loss = 5.1925\n",
      "Validation loss improved. Saving model...\n",
      "24600 tensor(4.6845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "24700 tensor(4.7756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "24800 tensor(4.6622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "24900 tensor(4.7735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "25000 tensor(4.7230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "25100 tensor(4.7723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "25200 tensor(4.7481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "25300 tensor(4.7136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 31: Train Loss = 4.7463, Val Loss = 5.1867\n",
      "Validation loss improved. Saving model...\n",
      "25400 tensor(4.6981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "25500 tensor(4.7011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "25600 tensor(4.7736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "25700 tensor(4.7134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "25800 tensor(4.7896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "25900 tensor(4.8251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "26000 tensor(4.6868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "26100 tensor(4.7671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 32: Train Loss = 4.7319, Val Loss = 5.1811\n",
      "Validation loss improved. Saving model...\n",
      "26200 tensor(4.7246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "26300 tensor(4.6799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "26400 tensor(4.7709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "26500 tensor(4.7356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "26600 tensor(4.7116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "26700 tensor(4.7140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "26800 tensor(4.7045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "26900 tensor(4.6736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 33: Train Loss = 4.7177, Val Loss = 5.1756\n",
      "Validation loss improved. Saving model...\n",
      "27000 tensor(4.6946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "27100 tensor(4.7034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "27200 tensor(4.6918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "27300 tensor(4.6862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "27400 tensor(4.7691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "27500 tensor(4.6764, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "27600 tensor(4.8038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "27700 tensor(4.6969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 34: Train Loss = 4.7039, Val Loss = 5.1703\n",
      "Validation loss improved. Saving model...\n",
      "27800 tensor(4.7056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "27900 tensor(4.6678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "28000 tensor(4.6770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "28100 tensor(4.7109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "28200 tensor(4.6980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "28300 tensor(4.7532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "28400 tensor(4.7011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "28500 tensor(4.6678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 35: Train Loss = 4.6903, Val Loss = 5.1652\n",
      "Validation loss improved. Saving model...\n",
      "28600 tensor(4.7367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "28700 tensor(4.6954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "28800 tensor(4.7084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "28900 tensor(4.7275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "29000 tensor(4.7301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "29100 tensor(4.6528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "29200 tensor(4.6618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "29300 tensor(4.7187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 36: Train Loss = 4.6769, Val Loss = 5.1603\n",
      "Validation loss improved. Saving model...\n",
      "29400 tensor(4.6656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "29500 tensor(4.6483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "29600 tensor(4.7053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "29700 tensor(4.7155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "29800 tensor(4.6603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "29900 tensor(4.6354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "30000 tensor(4.6967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 37: Train Loss = 4.6638, Val Loss = 5.1556\n",
      "Validation loss improved. Saving model...\n",
      "30100 tensor(4.6838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "30200 tensor(4.6283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "30300 tensor(4.6433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "30400 tensor(4.6393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "30500 tensor(4.6000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "30600 tensor(4.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "30700 tensor(4.6236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "30800 tensor(4.6747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 38: Train Loss = 4.6509, Val Loss = 5.1510\n",
      "Validation loss improved. Saving model...\n",
      "30900 tensor(4.6640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "31000 tensor(4.6552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "31100 tensor(4.6699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "31200 tensor(4.6336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "31300 tensor(4.6195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "31400 tensor(4.6622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "31500 tensor(4.5882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "31600 tensor(4.6196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 39: Train Loss = 4.6383, Val Loss = 5.1465\n",
      "Validation loss improved. Saving model...\n",
      "31700 tensor(4.6423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "31800 tensor(4.6581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "31900 tensor(4.6623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "32000 tensor(4.6216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "32100 tensor(4.6296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "32200 tensor(4.6272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "32300 tensor(4.6543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "32400 tensor(4.6765, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 40: Train Loss = 4.6258, Val Loss = 5.1422\n",
      "Validation loss improved. Saving model...\n",
      "32500 tensor(4.5743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "32600 tensor(4.5726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "32700 tensor(4.5141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "32800 tensor(4.5724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "32900 tensor(4.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "33000 tensor(4.5850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "33100 tensor(4.6714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "33200 tensor(4.6338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 41: Train Loss = 4.6136, Val Loss = 5.1381\n",
      "Validation loss improved. Saving model...\n",
      "33300 tensor(4.5783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "33400 tensor(4.5701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "33500 tensor(4.6193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "33600 tensor(4.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "33700 tensor(4.6381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "33800 tensor(4.6302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "33900 tensor(4.6481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "34000 tensor(4.5919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 42: Train Loss = 4.6015, Val Loss = 5.1341\n",
      "Validation loss improved. Saving model...\n",
      "34100 tensor(4.6205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "34200 tensor(4.6200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "34300 tensor(4.5386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "34400 tensor(4.4961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "34500 tensor(4.5542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "34600 tensor(4.5433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "34700 tensor(4.5982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "34800 tensor(4.5762, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 43: Train Loss = 4.5896, Val Loss = 5.1303\n",
      "Validation loss improved. Saving model...\n",
      "34900 tensor(4.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "35000 tensor(4.5919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "35100 tensor(4.6264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "35200 tensor(4.5114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "35300 tensor(4.5812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "35400 tensor(4.5827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "35500 tensor(4.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "35600 tensor(4.5615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 44: Train Loss = 4.5779, Val Loss = 5.1266\n",
      "Validation loss improved. Saving model...\n",
      "35700 tensor(4.5671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "35800 tensor(4.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "35900 tensor(4.5552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "36000 tensor(4.5648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "36100 tensor(4.5334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "36200 tensor(4.5482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "36300 tensor(4.5658, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "36400 tensor(4.5777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 45: Train Loss = 4.5664, Val Loss = 5.1230\n",
      "Validation loss improved. Saving model...\n",
      "36500 tensor(4.5516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "36600 tensor(4.5885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "36700 tensor(4.5996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "36800 tensor(4.5673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "36900 tensor(4.4454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "37000 tensor(4.5550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "37100 tensor(4.5746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "37200 tensor(4.5256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 46: Train Loss = 4.5551, Val Loss = 5.1196\n",
      "Validation loss improved. Saving model...\n",
      "37300 tensor(4.5455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "37400 tensor(4.5089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "37500 tensor(4.5486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "37600 tensor(4.5723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "37700 tensor(4.5083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "37800 tensor(4.5732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "37900 tensor(4.5630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "38000 tensor(4.5237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 47: Train Loss = 4.5439, Val Loss = 5.1163\n",
      "Validation loss improved. Saving model...\n",
      "38100 tensor(4.5620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "38200 tensor(4.5244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "38300 tensor(4.4901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "38400 tensor(4.5096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "38500 tensor(4.5260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "38600 tensor(4.5519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "38700 tensor(4.5358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "38800 tensor(4.5323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 48: Train Loss = 4.5329, Val Loss = 5.1131\n",
      "Validation loss improved. Saving model...\n",
      "38900 tensor(4.4758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "39000 tensor(4.4786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "39100 tensor(4.5392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "39200 tensor(4.4614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "39300 tensor(4.5137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "39400 tensor(4.4877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "39500 tensor(4.5539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 49: Train Loss = 4.5220, Val Loss = 5.1100\n",
      "Validation loss improved. Saving model...\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Learning curve",
   "id": "45c1b9220d02bb40"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T16:03:30.157040Z",
     "start_time": "2025-05-02T16:03:29.346266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(valid_losses, label='Val Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "f64c42e0dcad0d69",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Using the trained model for predictions",
   "id": "6cd05b2f9ea2d7e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T16:03:30.429472Z",
     "start_time": "2025-05-02T16:03:30.163556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_final = SimpleNeuralLM(vocab_size, embed_size, CONTEXT_SIZE)\n",
    "model_final.load_state_dict(torch.load(\"model_best.bin\", weights_only=True))"
   ],
   "id": "329e73ef7822c80a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T16:03:30.493975Z",
     "start_time": "2025-05-02T16:03:30.480125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_predictions(ctx):\n",
    "    model_input = torch.tensor([[vocab[x] for x in ctx]])\n",
    "    model_output = model_final(model_input)\n",
    "    top_indices = model_output.topk(5).indices[0].tolist()\n",
    "    return vocab.lookup_tokens(top_indices)\n",
    "\n",
    "get_predictions(['my', 'name', 'is', 'sherlock'])"
   ],
   "id": "2ff321fb6081ac7f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', 'holmes', '.', 'not', '?']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T16:03:30.553067Z",
     "start_time": "2025-05-02T16:03:30.540173Z"
    }
   },
   "cell_type": "code",
   "source": "get_predictions(['is', 'the', 'count', 'of'])",
   "id": "677566c5f0d23931",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['monte', 'morcerf', 'the', 'a', '<unk>']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T16:03:30.655478Z",
     "start_time": "2025-05-02T16:03:30.643178Z"
    }
   },
   "cell_type": "code",
   "source": "get_predictions(['the', 'count', 'of', 'monte'])",
   "id": "1d9a89981e12fa64",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cristo', 'cristo.', 'monte', 'morcerf', 'the']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T16:03:30.677236Z",
     "start_time": "2025-05-02T16:03:30.660488Z"
    }
   },
   "cell_type": "code",
   "source": "get_predictions([ 'i', 'wish', 'you', 'a'])",
   "id": "18b142b469686217",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to', '<unk>', 'good', 'have', 'will']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T16:03:30.737665Z",
     "start_time": "2025-05-02T16:03:30.724943Z"
    }
   },
   "cell_type": "code",
   "source": "get_predictions(['do', 'you', 'know', 'how'])",
   "id": "383c91f9d6d9b101",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['that', '?', 'it', ',', 'i']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T16:03:30.798511Z",
     "start_time": "2025-05-02T16:03:30.785538Z"
    }
   },
   "cell_type": "code",
   "source": "get_predictions([',', 'oh', 'my', 'god'])",
   "id": "61fdd1dad0075db4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!', ',', '’', 'lord', 'knows']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T16:03:30.900010Z",
     "start_time": "2025-05-02T16:03:30.887916Z"
    }
   },
   "cell_type": "code",
   "source": "get_predictions(['may', 'he', 'rest', 'in'])",
   "id": "249a400a63cca57c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'his', 'be', 'have', 'a']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T16:03:31.145505Z",
     "start_time": "2025-05-02T16:03:31.142930Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b743591af13edc93",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
